{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bGjYNEjPFiCE",
        "eD9R4p_JGS8j",
        "bwTcVNKCAoJt",
        "awq2lzbxBXgj",
        "AHm9t-_NGYDa",
        "WgzdNcHZGgch",
        "dDw9W32GaThb",
        "XXwxrNdCShlc",
        "l7fUcTZApdLB",
        "22ReLsjTEeCZ",
        "se7bKuAJbulU",
        "pNm8VPigbjay",
        "fYnY8Dp84Utn",
        "oAg57-_ib21t",
        "xwte93dQmMzJ",
        "WrxId6E4AZl-",
        "yJrfI4v50nnV",
        "wTVlUukw3Fcl",
        "y3gLbZhF3UAr",
        "_91uOB4kAOqz",
        "ngqgVtqrIsD-"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sbarbagnem/AdvancedProject/blob/master/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGjYNEjPFiCE",
        "colab_type": "text"
      },
      "source": [
        "# Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_AUBPWzkgSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall scikit-learn -y\n",
        "!pip install scikit-learn==0.21.3\n",
        "!apt-get install swig\n",
        "!pip install smac\n",
        "!pip install smac[all]\n",
        "!pip install smt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJr3vEODFZE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import ceil\n",
        "import xml.etree.ElementTree as ET\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import VGG16, ResNet50, MobileNet\n",
        "from keras.applications.vgg16 import preprocess_input as preprocess_input_vgg16\n",
        "from keras.applications.resnet50 import preprocess_input as preprocess_input_resnet50\n",
        "from keras.applications.mobilenet import preprocess_input as preprocess_input_mobilenet\n",
        "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, Flatten\n",
        "from keras import Model\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam, SGD\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from smac.configspace import ConfigurationSpace \n",
        "from smac.configspace import UniformFloatHyperparameter, UniformIntegerHyperparameter, CategoricalHyperparameter, InCondition\n",
        "from smac.configspace import Configuration # serve per costruire le configurazioni iniziali da passare alla funzione di minimizzazione\n",
        "from smac.scenario.scenario import Scenario\n",
        "from smac.facade.smac_bo_facade import SMAC4BO # bayesian optimization with GaussianProcess\n",
        "from smac.facade.smac_hpo_facade import SMAC4HPO # bayesian optimization with RandomForest\n",
        "from smac.optimizer.acquisition import EI, LCB, PI\n",
        "from smac.runhistory.runhistory import RunHistory # util class to collect all data of optimization\n",
        "from smac.initial_design.latin_hypercube_design import LHDesign\n",
        "from smac.stats.stats import Stats # util class to save history on directory\n",
        "from smac.utils.io.traj_logging import TrajLogger\n",
        "#from smac.optimizer.objective import average_cost\n",
        "\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD9R4p_JGS8j",
        "colab_type": "text"
      },
      "source": [
        "# Costant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jui_q9SGGXsi",
        "colab_type": "code",
        "outputId": "f8f357a2-7e8f-4eae-d47b-a5c5df5f4c09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "PATH_ANNOTATIONS = '/content/drive/My Drive/Laurea Magistrale/Adavanched Machine Learning/Progetto/Dataset/Train/Annotations/'\n",
        "PATH_MAIN = '/content/drive/My Drive/Laurea Magistrale/Adavanched Machine Learning/Progetto/Dataset/Train/Main/'\n",
        "PATH_IMAGES = '/content/drive/My Drive/Laurea Magistrale/Adavanched Machine Learning/Progetto/Dataset/Train/Images/'\n",
        "PATH_IMAGES_CROPPED_TRAIN = '/content/drive/My Drive/Laurea Magistrale/Adavanched Machine Learning/Progetto/Dataset/Train/Cropped_train/'\n",
        "PATH_IMAGES_CROPPED_VAL_TEST = '/content/drive/My Drive/Laurea Magistrale/Adavanched Machine Learning/Progetto/Dataset/Train/Cropped_val_test/'\n",
        "PATH_OPTIMIZATION = '/content/drive/My Drive/Laurea Magistrale/Adavanched Machine Learning/Progetto/Ottimizzazione/'\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "IM_SIZE = (128, 128)\n",
        "\n",
        "LABELS = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', \n",
        "          'car', 'cat', 'chair', 'cow', 'diningtable',\n",
        "          'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa',\n",
        "          'train', 'tvmonitor']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwTcVNKCAoJt",
        "colab_type": "text"
      },
      "source": [
        "# Directory for cropped images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shqDlbvsAsmi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creo 20 directory, una per ogni classe, per fare classificazione (flow_from_datframe) sulle immagini croppate\n",
        "def create_directories(path, labels):\n",
        "  for label in labels:\n",
        "    os.mkdir(os.path.join(path, label))\n",
        "\n",
        "create_folder_classes = False\n",
        "\n",
        "if create_folder_classes == True:\n",
        "  create_directories(PATH_IMAGES_CROPPED_TRAIN, LABELS)\n",
        "  create_directories(PATH_IMAGES_CROPPED_VAL_TEST, LABELS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awq2lzbxBXgj",
        "colab_type": "text"
      },
      "source": [
        "# Util function for mapping from label to #class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN3ewyc_BenA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dict_mapping(labels):\n",
        "  mapping = {}\n",
        "  for label,i in zip(labels, range(len(labels))):\n",
        "    mapping[label] = i\n",
        "  return mapping\n",
        "\n",
        "def from_label_to_number(mapping, label):\n",
        "  return mapping[label]\n",
        "\n",
        "def from_number_to_label(mapping, number):\n",
        "  for key, val in mapping.items(): \n",
        "    if val == number: \n",
        "      return key \n",
        "  return \"key doesn't exist\"\n",
        "\n",
        "def from_onehot_to_label(mapping, one_hot):\n",
        "  return from_number_to_label(mapping,np.where(one_hot == 1)[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EGlorv3K-NG",
        "colab_type": "code",
        "outputId": "ffb50cc9-ec21-4a7e-ad80-f57a7eb40cbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "mapping = create_dict_mapping(LABELS)\n",
        "print(mapping)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'aeroplane': 0, 'bicycle': 1, 'bird': 2, 'boat': 3, 'bottle': 4, 'bus': 5, 'car': 6, 'cat': 7, 'chair': 8, 'cow': 9, 'diningtable': 10, 'dog': 11, 'horse': 12, 'motorbike': 13, 'person': 14, 'pottedplant': 15, 'sheep': 16, 'sofa': 17, 'train': 18, 'tvmonitor': 19}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHm9t-_NGYDa",
        "colab_type": "text"
      },
      "source": [
        "# Crop and save image for class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P1zAHxAGdTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crop_image(img, x_min, y_min, x_max, y_max):\n",
        "  crop_img = img[y_min:y_max, x_min:x_max]\n",
        "  return crop_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QkTnM8cPtA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def list_images(path_images, path_txt, file_txt):\n",
        "  '''\n",
        "  creo liste immagini presenti in file_txt\n",
        "  '''\n",
        "  temp = []\n",
        "  f = open(os.path.join(path_txt, file_txt), \"r\")\n",
        "  for line in f.readlines():\n",
        "    temp.append(line.split('\\n')[0] + '.jpg')\n",
        "  list_images = [os.path.join(path_images, name) for name in temp]\n",
        "  print('Ho trovato ', len(list_images), 'per il file ', file_txt)\n",
        "  return list_images\n",
        "\n",
        "# creo liste immagini da train.txt e val.txt\n",
        "list_images_train = list_images(PATH_IMAGES, PATH_MAIN, 'train.txt')\n",
        "list_images_val = list_images(PATH_IMAGES, PATH_MAIN, 'val.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCnf_0tOQ687",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_and_crop(list_images, annotation_dir, path_to_save):\n",
        "  '''\n",
        "  leggo annotations dei file presenti nelle due liste di immagini \n",
        "  '''\n",
        "  for path in list_images:\n",
        "    image_name = path.split('/')[-1].split('.')[0] \n",
        "    print(image_name)\n",
        "    with open(os.path.join(annotation_dir, image_name + '.xml')) as f:\n",
        "      read_xml(f.read(), path, path_to_save)\n",
        "  return\n",
        "\n",
        "def read_xml(file_xml, path_image, path_to_save):\n",
        "  '''\n",
        "  leggo xml e per ogni box che trovo croppo e salvo\n",
        "  '''\n",
        "  img = cv2.imread(path_image)  \n",
        "  root = ET.XML(file_xml)\n",
        "  for _, child in enumerate(root):\n",
        "    if child.tag == 'object':\n",
        "      x_min = None\n",
        "      y_min = None\n",
        "      x_max = None\n",
        "      y_max = None\n",
        "      for subchild in child:\n",
        "        if subchild.tag == 'name':\n",
        "          name_object = subchild.text\n",
        "          #print(name_object)\n",
        "        if subchild.tag == 'bndbox':\n",
        "          for bndbox in subchild:\n",
        "            if bndbox.tag == 'xmin':\n",
        "              x_min = int(bndbox.text)\n",
        "              #print('x_min ', x_min)\n",
        "            if bndbox.tag == 'ymin':\n",
        "              y_min = int(bndbox.text)\n",
        "              #print('y_min ', y_min)\n",
        "            if bndbox.tag == 'xmax':\n",
        "              x_max = int(bndbox.text)\n",
        "              #print('x_max ', x_max)\n",
        "            if bndbox.tag == 'ymax':\n",
        "              y_max = int(bndbox.text)\n",
        "              #print('y_max ', y_max)\n",
        "        if(x_min!=None and y_min!=None and x_max!=None and y_max!=None):\n",
        "          image_cropped = crop_image(img, x_min, y_min, x_max, y_max)\n",
        "          x_min = None\n",
        "          y_min = None\n",
        "          x_max = None\n",
        "          y_max = None\n",
        "          #cv2_imshow(image_cropped)\n",
        "          save_image_cropped(name_object, image_cropped, path_to_save)\n",
        "  return \n",
        "\n",
        "def save_image_cropped(obj, img, path_to_save):\n",
        "  '''\n",
        "  salvo immagine croppata con numero progressivo in base \n",
        "  all'ultima presente nella cartella\n",
        "  '''\n",
        "  list_dir_classes = os.listdir(path_to_save)\n",
        "  for dir_class in list_dir_classes:\n",
        "    if dir_class == obj:\n",
        "      dir_temp = os.path.join(path_to_save,dir_class)\n",
        "      list_temp = os.listdir(dir_temp)\n",
        "      if list_temp == []:\n",
        "        cv2.imwrite(os.path.join(dir_temp, obj + '_1.jpg'), img)\n",
        "      else:\n",
        "        number_file = int(list_temp[-1].split('.')[0].split('_')[1]) + 1\n",
        "        cv2.imwrite(os.path.join(dir_temp, obj + '_' + str(number_file) + '.jpg'), img)\n",
        "  return\n",
        "\n",
        "read_and_crop(list_images=list_images_val, annotation_dir=PATH_ANNOTATIONS, path_to_save=PATH_IMAGES_CROPPED_VAL_TEST)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgzdNcHZGgch",
        "colab_type": "text"
      },
      "source": [
        "# Util function to create generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMtwpZ_kGfsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_generator( batch_size, im_size, base_net, train_directory, val_directory, labels,\n",
        "                      validation_split, aug, augment_params):\n",
        "  \n",
        "  if base_net == 'vgg16':\n",
        "    preprocess_function = preprocess_input_vgg16\n",
        "  elif base_net == 'mobilenet':\n",
        "    preprocess_function = preprocess_input_mobilenet\n",
        "  elif base_net == 'resnet':\n",
        "    preprocess_function = preprocess_input_resnet50\n",
        "\n",
        "  if not(aug):\n",
        "    img_gen_train = ImageDataGenerator(preprocessing_function=preprocess_function)\n",
        "  elif aug:\n",
        "    img_gen_train = ImageDataGenerator( preprocessing_function=preprocess_function,\n",
        "                                        **augment_params)  \n",
        "\n",
        "\n",
        "  img_gen_val = ImageDataGenerator( preprocessing_function=preprocess_function,\n",
        "                                    validation_split = validation_split\n",
        "                                  )\n",
        "    \n",
        "  train_gen = img_gen_train.flow_from_directory(\n",
        "      directory = train_directory,\n",
        "      shuffle=True,\n",
        "      class_mode='categorical',\n",
        "      target_size=im_size,\n",
        "      batch_size=batch_size,\n",
        "      classes=labels,\n",
        "      seed=42\n",
        "  )\n",
        "\n",
        "  val_gen = img_gen_val.flow_from_directory(\n",
        "      directory = val_directory,\n",
        "      shuffle=False,\n",
        "      class_mode='categorical',\n",
        "      target_size=im_size,\n",
        "      batch_size=batch_size,\n",
        "      subset='training',\n",
        "      classes=labels,\n",
        "      seed=42\n",
        "  )\n",
        "\n",
        "  test_gen = img_gen_val.flow_from_directory(\n",
        "      directory = val_directory,\n",
        "      shuffle=False,\n",
        "      class_mode='categorical',\n",
        "      target_size=im_size,\n",
        "      batch_size=batch_size,\n",
        "      subset='validation',\n",
        "      classes=labels,\n",
        "      seed=42\n",
        "  )\n",
        "\n",
        "  return train_gen, val_gen, test_gen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDw9W32GaThb",
        "colab_type": "text"
      },
      "source": [
        "# Util function for frequency classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teCq1HPhaXTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_frequency_from_generator(generator):\n",
        "  mapping = generator.class_indices\n",
        "  classes, count = np.unique(generator.labels, return_counts=True)\n",
        "  labels = [from_number_to_label(mapping, label) for label in classes]\n",
        "  freq = count\n",
        "  return labels, freq\n",
        "\n",
        "def normalize_frequency(freq):\n",
        "  min_freq = np.min(freq)\n",
        "  weigh = [min_freq/x for x in freq]\n",
        "  return weigh * freq, weigh\n",
        "\n",
        "def plot_label_frequency(labels, freq):\n",
        "  freq = freq / np.sum(freq)\n",
        "  l = list(range(1, len(labels)+1))\n",
        "  plt.barh(l, width=freq, height=0.5)\n",
        "  plt.yticks(l, labels, rotation='horizontal')\n",
        "  plt.show()\n",
        "\n",
        "def plot_stacked_bar_freq(labels, freq, freq_normalize):\n",
        "  N = len(labels)\n",
        "  ind = np.arange(N)    # the x locations for the groups\n",
        "  width = 0.35       # the width of the bars: can also be len(x) sequence\n",
        "\n",
        "  p1 = plt.bar(ind, freq, width)\n",
        "  p2 = plt.bar(ind, freq_normalize, width)\n",
        "\n",
        "  plt.ylabel('Frequency')\n",
        "  plt.legend((p1[0], p2[0]), ('Freq', 'Freq_normalize'))\n",
        "\n",
        "  plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXwxrNdCShlc",
        "colab_type": "text"
      },
      "source": [
        "# Util function to create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etwOZM2GSjL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(base_net, freeze_all, freeze_to, dense, dropout, drop_out, im_size):\n",
        "  if base_net == 'vgg16':\n",
        "    base_model = VGG16(weights = 'imagenet', input_shape=im_size + (3,), include_top = False)\n",
        "  elif base_net == 'resnet':\n",
        "    base_model = ResNet50(weights = 'imagenet', input_shape=im_size + (3,), include_top = False)\n",
        "  elif base_net == 'mobilenet':\n",
        "    base_model = MobileNet(weights = 'imagenet', input_shape=im_size + (3,), include_top = False)\n",
        "\n",
        "  #x = base_model.output\n",
        "  x = base_model.layers[-1].output\n",
        "  #x = Flatten()(x)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  for layer in dense:\n",
        "    x = Dense(layer, activation='relu')(x)\n",
        "    if drop_out:\n",
        "      x = Dropout(dropout)(x)\n",
        "  predictions = Dense(20, activation = 'softmax')(x)\n",
        "  model = Model(input = base_model.input, output = predictions)\n",
        "\n",
        "  if freeze_all == True:\n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable=False\n",
        "  else:\n",
        "    for layer in base_model.layers[:freeze_to]:\n",
        "      layer.trainable=False\n",
        "    for layer in model.layers[freeze_to:]:\n",
        "      layer.trainable = True\n",
        "      \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7fUcTZApdLB",
        "colab_type": "text"
      },
      "source": [
        "# Util function to plot performance epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXAGRUyipg-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_performance(history):\n",
        "  plt.plot(history.history['categorical_accuracy'])\n",
        "  plt.plot(history.history['val_categorical_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()\n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22ReLsjTEeCZ",
        "colab_type": "text"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se7bKuAJbulU",
        "colab_type": "text"
      },
      "source": [
        "## Set up generator and model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDNTdRNpGBpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_net = 'mobilenet'\n",
        "\n",
        "augment_params = dict(  rotation_range=30,\n",
        "                        #width_shift_range=0.2,\n",
        "                        #height_shift_range=0.2,\n",
        "                        horizontal_flip=True,\n",
        "                        #brightness_range=[0.4,1.0],\n",
        "                        zoom_range=0.1\n",
        "                      )\n",
        "\n",
        "train_gen, val_gen, test_gen = create_generator(batch_size=BATCH_SIZE, \n",
        "                                                im_size=IM_SIZE, \n",
        "                                                base_net=base_net, \n",
        "                                                train_directory=PATH_IMAGES_CROPPED_TRAIN, \n",
        "                                                val_directory=PATH_IMAGES_CROPPED_VAL_TEST, \n",
        "                                                labels=LABELS,\n",
        "                                                validation_split=0.7,\n",
        "                                                aug=True,\n",
        "                                                augment_params=augment_params\n",
        "                                                )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR4bO3SF_-EN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x,y = train_gen.next()\n",
        "for i in range(0,63):\n",
        "    image = x[i]\n",
        "    plt.figure()\n",
        "    plt.imshow(image)\n",
        "    plt.title(from_onehot_to_label(mapping, y[i]))\n",
        "    plt.show\n",
        "\n",
        "train_gen.reset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNm8VPigbjay",
        "colab_type": "text"
      },
      "source": [
        "## Analyze frequency label in generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7QYMSTWbaof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels, freq = get_frequency_from_generator(train_gen)\n",
        "plot_label_frequency(labels, freq)\n",
        "freq_normalize, weigh = normalize_frequency(freq)\n",
        "#plot_label_frequency(labels, freq_normalize)\n",
        "plot_stacked_bar_freq(labels, freq, freq_normalize)\n",
        "\n",
        "# dict for weigh model\n",
        "weigh_class = {}\n",
        "for label,i in zip(labels, weigh):\n",
        "  weigh_class[from_label_to_number(mapping, label)] = i\n",
        "\n",
        "weigh_class_sklearn = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(train_gen.classes),\n",
        "                                                 train_gen.classes)\n",
        "\n",
        "pesi = dict()\n",
        "\n",
        "for label,peso in zip(range(len(LABELS)), weigh_class_sklearn):\n",
        "  pesi[label] = peso\n",
        "plot_stacked_bar_freq(labels, freq, freq*weigh_class_sklearn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYnY8Dp84Utn",
        "colab_type": "text"
      },
      "source": [
        "## Focal loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf8VcmVF4Xn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def focal_loss(gamma=2., alpha=0.25):\n",
        "\n",
        "    gamma = float(gamma)\n",
        "    alpha = float(alpha)\n",
        "\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"Focal loss for multi-classification\n",
        "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
        "        Notice: y_pred is probability after softmax\n",
        "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
        "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
        "        Focal Loss for Dense Object Detection\n",
        "        https://arxiv.org/abs/1708.02002\n",
        "\n",
        "        Arguments:\n",
        "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
        "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
        "\n",
        "        Keyword Arguments:\n",
        "            gamma {float} -- (default: {2.0})\n",
        "            alpha {float} -- (default: {4.0})\n",
        "\n",
        "        Returns:\n",
        "            [tensor] -- loss.\n",
        "        \"\"\"\n",
        "        epsilon = 1.e-9\n",
        "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
        "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
        "\n",
        "        model_out = tf.add(y_pred, epsilon)\n",
        "        ce = tf.multiply(y_true, -tf.log(model_out))\n",
        "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
        "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
        "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "        return tf.reduce_mean(reduced_fl)\n",
        "    return focal_loss_fixed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAg57-_ib21t",
        "colab_type": "text"
      },
      "source": [
        "## Set up iper-parameter for fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QSFiR2Ab6v1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = 'binary_crossentropy'\n",
        "optimizer = 'adam'\n",
        "reduce_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, \n",
        "                                      verbose=1, mode='auto', min_delta=0.0001, \n",
        "                                      cooldown=0, min_lr=0.00001)\n",
        "early_stop = EarlyStopping(monitor='val_loss', \n",
        "                           patience=3, \n",
        "                           verbose=1\n",
        "                           )\n",
        "metrics = ['categorical_accuracy']\n",
        "epochs = 30\n",
        "steps_per_epoch = ceil(train_gen.n / train_gen.batch_size)\n",
        "validation_steps = ceil(val_gen.n / val_gen.batch_size)\n",
        "class_weights = pesi\n",
        "dense = [128, 128]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9HmoEWOUkkU",
        "colab_type": "code",
        "outputId": "08efe211-c152-4a32-9379-93a3a6f870aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        }
      },
      "source": [
        "model = create_model( base_net='mobilenet', \n",
        "                      freeze_all=False, \n",
        "                      freeze_to=74, \n",
        "                      dense=dense,\n",
        "                      dropout=0.2,\n",
        "                      drop_out=True,\n",
        "                      im_size=IM_SIZE\n",
        "                     )\n",
        "\n",
        "#model.summary()\n",
        "\n",
        "#for i,layer in zip(range(len(model.layers)), model.layers):\n",
        "#  print(i, ' ', layer, layer.trainable)\n",
        "\n",
        "model.compile(loss=loss, \n",
        "              optimizer=optimizer, \n",
        "              metrics=metrics\n",
        "              )\n",
        "\n",
        "net_history = model.fit_generator(train_gen, epochs=epochs, verbose=1,\n",
        "                                  validation_data = val_gen,\n",
        "                                  steps_per_epoch = steps_per_epoch,\n",
        "                                  validation_steps = validation_steps,\n",
        "                                  callbacks = [early_stop, reduce_on_plateau],\n",
        "                                  workers = 4,\n",
        "                                  use_multiprocessing=True,\n",
        "                                  #class_weight = class_weights\n",
        "                                  )\n",
        "\n",
        "train_gen.reset()\n",
        "val_gen.reset()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_128_tf_no_top.h5\n",
            "17227776/17225924 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqNkpcddZLB0",
        "colab_type": "code",
        "outputId": "239b2031-c4bd-4a47-cfe4-b92990bd0e85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "source": [
        "plot_performance(net_history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhDHGGL8sQRhjjPHLEoQxxhi//h+ZbtgJVuLxeAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwte93dQmMzJ",
        "colab_type": "text"
      },
      "source": [
        "# Ottimizzazione"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrxId6E4AZl-",
        "colab_type": "text"
      },
      "source": [
        "## CNN_for_optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T3GwCMTMVtZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataframe_path_class(path_images):\n",
        "  df = pd.DataFrame(columns=['absolute_path', 'class'])\n",
        "  list_dir = os.listdir(path_images)\n",
        "  for sub_dir in list_dir:\n",
        "    list_images = os.listdir(os.path.join(path_images, sub_dir))  \n",
        "    for image in list_images:\n",
        "      df = df.append({'absolute_path': os.path.join(path_images, sub_dir, image),\n",
        "                      'class' : str(sub_dir)} , \n",
        "                     ignore_index=True)\n",
        "  return df\n",
        "\n",
        "#pd.set_option('max_colwidth', -1)\n",
        "df_train = dataframe_path_class(PATH_IMAGES_CROPPED_TRAIN)\n",
        "df_val_test = dataframe_path_class(PATH_IMAGES_CROPPED_VAL_TEST)\n",
        "\n",
        "# creo df_test che uso solo dopo ottimizzazione iperparametri\n",
        "df_test, df_val = train_test_split(df_val_test, test_size=0.5)\n",
        "\n",
        "# unisco df_val a df_train per avere un train generale su cui eseguire k-cross-fold validation\n",
        "df_train = df_train.append(df_val, ignore_index=True)\n",
        "\n",
        "# salvo i due dataframe\n",
        "df_train.to_csv(PATH_OPTIMIZATION + 'train.csv')\n",
        "df_test.to_csv(PATH_OPTIMIZATION + 'test.csv')\n",
        "\n",
        "# da df_train tiro fuori degli esempi che userò come test nell k-cross-fold-validation\n",
        "#df_train, df_test = train_test_split(df_train, test_size=0.2)\n",
        "\n",
        "#df_train.to_csv(PATH_OPTIMIZATION + 'train_for_k_cross.csv')\n",
        "#df_test.tocsv(PATH_OPTIMIZATION + 'test_for_k_cross.csv')\n",
        "\n",
        "df_train = pd.read_csv(PATH_OPTIMIZATION + 'train.csv')\n",
        "df_test = pd.read_csv(PATH_OPTIMIZATION + 'test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YRPDR-AKNLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "def k_cross_fold_validation(model, \n",
        "                        df_train,\n",
        "                        early_stop,\n",
        "                        reduce_on_plateau):\n",
        "'''\n",
        "\n",
        "## Training with K-fold cross validation\n",
        "kf = KFold(n_splits=3, random_state=None, shuffle=True)\n",
        "\n",
        "accuracy_on_fold = []\n",
        "\n",
        "trainGenerator = ImageDataGenerator(preprocessing_function=preprocess_input_mobilenet,\n",
        "                                  rotation_range=0.2,\n",
        "                                  horizontal_flip=True,\n",
        "                                  zoom_range=0.1)\n",
        "valGenerator = ImageDataGenerator(preprocessing_function=preprocess_input_mobilenet)\n",
        "\n",
        "i = 1\n",
        "for train_index, val_index in kf.split(df_train):\n",
        "  trainData = df_train.iloc[train_index,:]\n",
        "\n",
        "  # divido ulteriormente il train per avere un validation con cui poter usare \n",
        "  # early stopping e reduce_learning_rate_on_plateau durante fit\n",
        "  trainData, valData = train_test_split(trainData, test_size=0.2)\n",
        "\n",
        "  testData = df_train.iloc[val_index,:]\n",
        "\n",
        "  print(\"=========================================\")\n",
        "  print(\"====== K Fold Validation step => %d =======\" % (i))\n",
        "  print(\"=========================================\")\n",
        "\n",
        "  print(\"Flow from train dataframe\")\n",
        "  train_gen = trainGenerator.flow_from_dataframe(\n",
        "    dataframe = trainData,\n",
        "    x_col='absolute_path',\n",
        "    y_col='class',\n",
        "    shuffle=True,\n",
        "    class_mode='categorical',\n",
        "    target_size=IM_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    classes=LABELS,\n",
        "    #seed=42\n",
        "  )\n",
        "\n",
        "  print(\"Flow from val dataframe\")\n",
        "  val_gen = valGenerator.flow_from_dataframe(\n",
        "    dataframe = valData,\n",
        "    x_col='absolute_path',\n",
        "    y_col='class',\n",
        "    shuffle=False,\n",
        "    class_mode='categorical',\n",
        "    target_size=IM_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    classes=LABELS,\n",
        "    #seed=42\n",
        "  )\n",
        "\n",
        "  print(\"Flow from test dataframe\")\n",
        "  test_gen = valGenerator.flow_from_dataframe(\n",
        "    dataframe = testData,\n",
        "    x_col='absolute_path',\n",
        "    y_col='class',\n",
        "    shuffle=False,\n",
        "    class_mode='categorical',\n",
        "    target_size=IM_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    classes=LABELS,\n",
        "    #seed=42\n",
        "  ) \n",
        "\n",
        "  step_train = ceil(train_gen.n/train_gen.batch_size)\n",
        "  step_val = ceil(val_gen.n/val_gen.batch_size)\n",
        "  step_test = ceil(test_gen.n/test_gen.batch_size)\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', \n",
        "            optimizer='adam', \n",
        "            metrics=['categorical_accuracy']\n",
        "            )\n",
        "\n",
        "  print(\"Inizio fit\")\n",
        "  model.fit_generator(train_gen, \n",
        "                      epochs=40, \n",
        "                      verbose=1,\n",
        "                      validation_data = val_gen,\n",
        "                      steps_per_epoch = step_train,\n",
        "                      validation_steps = step_val,\n",
        "                      callbacks = [early_stop, reduce_on_plateau],\n",
        "                      #workers = 4,\n",
        "                      #use_multiprocessing=True\n",
        "                  )\n",
        "\n",
        "  # test on testData\n",
        "  print(\"Predict on test\")\n",
        "  predictions = model.predict_generator(test_gen, \n",
        "                                        steps=step_test,\n",
        "                                        #workers=4, \n",
        "                                        #use_multiprocessing=True\n",
        "                                        )\n",
        "\n",
        "  model.reset_states()\n",
        "\n",
        "  predict_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "  accuracy_on_fold.append(accuracy_score(y_true=test_gen.classes, \n",
        "                                         y_pred=predict_classes))\n",
        "\n",
        "  i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obHvuHlsxrCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_accuracy = accuracy_on_fold\n",
        "\n",
        "print(np.mean(temp_accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxZWnDcoAY_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_for_optimization(cfg):\n",
        "\n",
        "  # creo modello sulla base delle configurazioni in cfg\n",
        "  if cfg['number_layer'] == 2:\n",
        "    dense = [cfg['number_first_layer'], cfg['number_second_layer']]\n",
        "  elif cfg['number_layer'] == 1:\n",
        "    dense = [cfg['number_first_layer']]\n",
        "\n",
        "  model = create_model( base_net='mobilenet', \n",
        "                        freeze_all=False, \n",
        "                        freeze_to=74, \n",
        "                        dense=dense,\n",
        "                        dropout=cfg['dropout'],\n",
        "                        drop_out=True,\n",
        "                        im_size=IM_SIZE\n",
        "                      )\n",
        "  \n",
        "  # compilo\n",
        "  if cfg['optimizer'] == 'SGD':\n",
        "    optimizer = SGD(lr=cgf['learning_rate'], momentum=cfg['momentum'])\n",
        "    if cfg['nestorov'] == True:\n",
        "      optimizer.nestorov = True\n",
        "  elif cfg['optimizer'] == 'adam':\n",
        "    optimizer = Adam(lr=cfg['learning_rate'])\n",
        "\n",
        "  model.compile(loss='binary_crossentropy', \n",
        "              optimizer=optimizer, \n",
        "              metrics=['categorical_accuracy']\n",
        "              )\n",
        "  \n",
        "  # fitto su generator (posso passarlo come parametro o globale??)\n",
        "  reduce_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, \n",
        "                                        verbose=1, mode='auto', min_delta=0.0001, \n",
        "                                        cooldown=0, min_lr=0.00001)\n",
        "  early_stop = EarlyStopping(monitor='val_loss', \n",
        "                            patience=3, \n",
        "                            verbose=1\n",
        "                            )\n",
        "  net_history = model.fit_generator(train_gen, epochs=50, verbose=0,\n",
        "                                  steps_per_epoch = steps_per_epoch,\n",
        "                                  callbacks = [early_stop, reduce_on_plateau],\n",
        "                                  workers = 4,\n",
        "                                  use_multiprocessing=True\n",
        "                                  )\n",
        "  \n",
        "  # calcolo accuratezza su validation \n",
        "  # return 1 - accuratezza"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJrfI4v50nnV",
        "colab_type": "text"
      },
      "source": [
        "## Configuration space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgQ0AAgxmP7i",
        "colab_type": "code",
        "outputId": "a91aac21-c1a3-42ab-ac91-c0d1f5b32fd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "cs = ConfigurationSpace()\n",
        "\n",
        "# iper-parametri da ottimizzare\n",
        "'''\n",
        "  Optimizier: categorical ('adam', 'SGD')\n",
        "  Learning_rate: uniform_float [0.01, 0.00001]\n",
        "  Momentum: categorical and condition (True,False) if 'SGD'\n",
        "  Nestorov: uniform_float and condition [0.9, 0.8] if 'SGD'\n",
        "  Dropout: uniform_float [0.2,0.4]\n",
        "  Number_fully_connected: categorical (1,2)\n",
        "  Number_neurons_first_layer: uniform_integer [256, 1024]\n",
        "  Numebr_neurons_second_layer: uniform_integer and condition [256,1024] if number_fully_connected==2\n",
        "'''\n",
        "optimizier_param = CategoricalHyperparameter(name='optimizier',\n",
        "                                             choices=['adam', 'SGD'],\n",
        "                                             default_value='SGD')\n",
        "\n",
        "lr_param = UniformFloatHyperparameter(name=\"learning_rate\", \n",
        "                                      lower=0.00001, \n",
        "                                      upper=0.01, \n",
        "                                      default_value=0.001)\n",
        "\n",
        "momentum_param = UniformFloatHyperparameter(name='momentum',\n",
        "                                            lower=0.1,\n",
        "                                            upper=0.9,\n",
        "                                            default_value=0.5\n",
        "                                            )\n",
        "cond_momentum = InCondition(child=momentum_param, \n",
        "                            parent=optimizier_param, \n",
        "                            values=['SGD'])\n",
        "\n",
        "nestorov_param = CategoricalHyperparameter(name=\"nestorov\", \n",
        "                                           choices=[True, False], \n",
        "                                           default_value=False)\n",
        "cond_nestorov = InCondition(child=nestorov_param, \n",
        "                            parent=optimizier_param, \n",
        "                            values=['SGD'])\n",
        "\n",
        "dropout_param = UniformFloatHyperparameter(name='dropout',\n",
        "                                           lower=0.2,\n",
        "                                           upper=0.4,\n",
        "                                           default_value=0.3)\n",
        "\n",
        "number_layer_param = CategoricalHyperparameter(name='number_layer',\n",
        "                                         choices=[1,2],\n",
        "                                         default_value=2)\n",
        "\n",
        "neurons_first_layer_param = UniformIntegerHyperparameter(name='number_first_layer',\n",
        "                                                   lower=256,\n",
        "                                                   upper=1024,\n",
        "                                                   default_value=512)\n",
        "\n",
        "neurons_second_layer_param = UniformIntegerHyperparameter(name='number_second_layer',\n",
        "                                                   lower=256,\n",
        "                                                   upper=1024,\n",
        "                                                   default_value=512)\n",
        "cond_second_layer = InCondition(child=neurons_second_layer,\n",
        "                                parent=number_layer,\n",
        "                                values=[2])\n",
        "\n",
        "cs.add_hyperparameters([optimizier_param, \n",
        "                        lr_param,\n",
        "                        momentum_param,\n",
        "                        nestorov_param,\n",
        "                        dropout_param,\n",
        "                        number_layer_param,\n",
        "                        neurons_first_layer_param,\n",
        "                        neurons_second_layer_param\n",
        "                        ])\n",
        "cs.add_conditions([cond_momentum,\n",
        "                   cond_nestorov,\n",
        "                   cond_second_layer])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[momentum | optimizier in {'SGD'},\n",
              " nestorov | optimizier in {'SGD'},\n",
              " number_second_layer | number_layer in {2}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTVlUukw3Fcl",
        "colab_type": "text"
      },
      "source": [
        "## Scenario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-YMAPtn3HM0",
        "colab_type": "code",
        "outputId": "90bd2e4c-f8ad-4dfd-9805-47eedf375df7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "scenario = Scenario({\"run_obj\": \"quality\",  \n",
        "                     \"runcount-limit\": 20, # 15 + 5 configurazioni iniziali   \n",
        "                     \"cs\": cs,               \n",
        "                     \"deterministic\": \"true\"\n",
        "                     })"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:smac.utils.io.cmd_reader.CMDReader:Output to smac3-output_2020-03-09_10:35:52_946839\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3gLbZhF3UAr",
        "colab_type": "text"
      },
      "source": [
        "## Initial configuratino (LHS) and util class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fohHZ34m3X4a",
        "colab_type": "code",
        "outputId": "cafe1f06-9921-4c47-9b34-4bad871a25b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# All statistics collected during configuration run. Written to output-directory to be restored\n",
        "stat = Stats(scenario=scenario)\n",
        "\n",
        "\n",
        "traj_logger  = TrajLogger(output_dir=PATH_OPTIMIZATION + 'traj_logger/',\n",
        "                          stats=stat)\n",
        "\n",
        "run_history = RunHistory()\n",
        "\n",
        "initial_config = LHDesign(cs=cs,\n",
        "                          rng=42,\n",
        "                          traj_logger=traj_logger,\n",
        "                          ta_run_limit=5,\n",
        "                          init_budget=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:smac.initial_design.latin_hypercube_design.LHDesign:Running initial design for 5 configurations\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_91uOB4kAOqz",
        "colab_type": "text"
      },
      "source": [
        "## Optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfqB26ESAQP5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smac = SMAC4HPO(scenario=scenario,\n",
        "                tae_runnner=cnn_for_optimization,\n",
        "                runhistory=run_history,\n",
        "                acquisition_function=PI,\n",
        "                initial_design=initial_config,\n",
        "                stats=stat,\n",
        "                )\n",
        "\n",
        "incumbent = smac.optimize()\n",
        "\n",
        "inc_value = cnn_for_optimization(incumbent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngqgVtqrIsD-",
        "colab_type": "text"
      },
      "source": [
        "# Performance on test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2GI2JyjIvBU",
        "colab_type": "code",
        "outputId": "c7c27d9c-3bf9-4b16-d79a-aa2c60f49cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "def performance_on_test(model, test_generator):\n",
        "  predictions = model.predict_generator(test_generator, \n",
        "                          steps=ceil(test_generator.n / test_generator.batch_size), \n",
        "                          workers=4, \n",
        "                          use_multiprocessing=True)\n",
        "  predict_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "  performance = classification_report(  y_true = test_generator.classes, \n",
        "                                        y_pred = predict_classes,\n",
        "                                        target_names=LABELS\n",
        "  )\n",
        "\n",
        "  return performance\n",
        "\n",
        "result = performance_on_test(model, test_gen)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   aeroplane       0.89      0.79      0.83       338\n",
            "     bicycle       0.81      0.80      0.80       266\n",
            "        bird       0.87      0.66      0.75       440\n",
            "        boat       0.83      0.74      0.78       343\n",
            "      bottle       0.78      0.73      0.75       513\n",
            "         bus       0.90      0.82      0.86       224\n",
            "         car       0.79      0.87      0.82       821\n",
            "         cat       0.90      0.82      0.86       432\n",
            "       chair       0.67      0.82      0.73      1014\n",
            "         cow       0.57      0.67      0.62       242\n",
            " diningtable       0.83      0.63      0.71       261\n",
            "         dog       0.82      0.77      0.79       541\n",
            "       horse       0.74      0.79      0.76       261\n",
            "   motorbike       0.84      0.70      0.77       263\n",
            "      person       0.86      0.93      0.89      3577\n",
            " pottedplant       0.90      0.74      0.81       379\n",
            "       sheep       0.86      0.71      0.78       339\n",
            "        sofa       0.70      0.45      0.55       270\n",
            "       train       0.93      0.80      0.86       230\n",
            "   tvmonitor       0.86      0.86      0.86       289\n",
            "\n",
            "    accuracy                           0.82     11043\n",
            "   macro avg       0.82      0.75      0.78     11043\n",
            "weighted avg       0.82      0.82      0.81     11043\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYQLGSJSQEBG",
        "colab_type": "text"
      },
      "source": [
        "# TODO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxbSwxZDQFYC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# funzione che prende in input flow from dataframe e ritorna pickle con tutte le immagini"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}